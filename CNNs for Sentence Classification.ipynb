{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuIesOJioX-_",
        "outputId": "cdb2969d-6cbe-422b-9b50-40bbae69526e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
          ]
        }
      ],
      "source": [
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "%matplotlib inline\n",
        "import collections\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import tensorflow as tf\n",
        "import random\n",
        "import zipfile\n",
        "from matplotlib import pylab\n",
        "from six.moves import range\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import tensorflow as tf\n",
        "\n",
        "seed = 54321\n",
        "\n",
        "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KzQMJVLoo18"
      },
      "source": [
        "# Downloading and checking the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn_QpGQTonFW",
        "outputId": "de7bf878-9cb9-4b75-ea0c-84ffd39b2ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found and verified data/train_5500.label\n",
            "Found and verified data/TREC_10.label\n"
          ]
        }
      ],
      "source": [
        "url = 'http://cogcomp.org/Data/QA/QC/'\n",
        "dir_name = 'data'\n",
        "\n",
        "def download_data(dir_name, filename, expected_bytes):\n",
        "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "\n",
        "    os.makedirs(dir_name, exist_ok=True)\n",
        "    if not os.path.exists(os.path.join(dir_name,filename)):\n",
        "        filepath, _ = urlretrieve(url + filename, os.path.join(dir_name,filename))\n",
        "    else:\n",
        "        filepath = os.path.join(dir_name, filename)\n",
        "\n",
        "    statinfo = os.stat(filepath)\n",
        "    if statinfo.st_size == expected_bytes:\n",
        "        print('Found and verified %s' % filepath)\n",
        "    else:\n",
        "        print(statinfo.st_size)\n",
        "        raise Exception(\n",
        "          'Failed to verify ' + filepath + '. Can you get to it with a browser?')\n",
        "\n",
        "    return filepath\n",
        "\n",
        "train_filename = download_data(dir_name, 'train_5500.label', 335858)\n",
        "test_filename = download_data(dir_name, 'TREC_10.label',23354)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqGljCqWozA5"
      },
      "source": [
        "# Loading and preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPt9l7MMowkM",
        "outputId": "31eac06d-87a1-472a-ced1-ff7c6e003c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_questions has 5452 questions / 5452 labels\n",
            "Some samples\n",
            "\thow did serfdom develop in and then leave russia ? / cat - DESC / sub_cat - manner\n",
            "\twhat films featured the character popeye doyle ? / cat - ENTY / sub_cat - cremat\n",
            "\thow can i find a list of celebrities ' real names ? / cat - DESC / sub_cat - manner\n",
            "\twhat fowl grabs the spotlight after the chinese year of the monkey ? / cat - ENTY / sub_cat - animal\n",
            "\twhat is the full form of .com ? / cat - ABBR / sub_cat - exp\n",
            "\twhat contemptible scoundrel stole the cork from my lunch ? / cat - HUM / sub_cat - ind\n",
            "\twhat team did baseball 's st. louis browns become ? / cat - HUM / sub_cat - gr\n",
            "\twhat is the oldest profession ? / cat - HUM / sub_cat - title\n",
            "\twhat are liver enzymes ? / cat - DESC / sub_cat - def\n",
            "\tname the scar-faced bounty hunter of the old west . / cat - HUM / sub_cat - ind\n",
            "\n",
            "test_questions has 500 questions / 500 labels\n",
            "Some samples\n",
            "\thow far is it from denver to aspen ? / cat - NUM / sub_cat - dist\n",
            "\twhat county is modesto , california in ? / cat - LOC / sub_cat - city\n",
            "\twho was galileo ? / cat - HUM / sub_cat - desc\n",
            "\twhat is an atom ? / cat - DESC / sub_cat - def\n",
            "\twhen did hawaii become a state ? / cat - NUM / sub_cat - date\n",
            "\thow tall is the sears building ? / cat - NUM / sub_cat - dist\n",
            "\tgeorge bush purchased a small interest in which baseball team ? / cat - HUM / sub_cat - gr\n",
            "\twhat is australia 's national flower ? / cat - ENTY / sub_cat - plant\n",
            "\twhy does the moon turn orange ? / cat - DESC / sub_cat - reason\n",
            "\twhat is autism ? / cat - DESC / sub_cat - def\n"
          ]
        }
      ],
      "source": [
        "def read_data(filename):\n",
        "    '''\n",
        "    Read data from a file with given file name\n",
        "    Returns a list of strings where each string is a lowercase word\n",
        "    '''\n",
        "\n",
        "    # Holds question strings, categories, and subcategories\n",
        "    # category/sub_cateory definitions: https://cogcomp.seas.upenn.edu/Data/QA/QC/definition.html\n",
        "    questions, categories, sub_categories = [], [], []\n",
        "\n",
        "    with open(filename,'r',encoding='latin-1') as f:\n",
        "        # Read each line\n",
        "        for row in f:\n",
        "            # Each string has format <cat>:<sub cat> <question>\n",
        "            # Split by : to separate cat and (sub_cat + question)\n",
        "            row_str = row.split(\":\")\n",
        "            cat, sub_cat_and_question = row_str[0], row_str[1]\n",
        "            tokens = sub_cat_and_question.split(' ')\n",
        "            # The first word in sub_cat_and_question is the sub category.\n",
        "            # rest is the question\n",
        "            sub_cat, question = tokens[0], ' '.join(tokens[1:])\n",
        "\n",
        "            questions.append(question.lower().strip())\n",
        "            categories.append(cat)\n",
        "            sub_categories.append(sub_cat)\n",
        "\n",
        "\n",
        "    return questions, categories, sub_categories\n",
        "\n",
        "train_questions, train_categories, train_sub_categories = read_data(train_filename)\n",
        "test_questions, test_categories, test_sub_categories = read_data(test_filename)\n",
        "\n",
        "n_samples = 10\n",
        "print(f\"train_questions has {len(train_questions)} questions / {len(train_categories)} labels\")\n",
        "print(\"Some samples\")\n",
        "for question, cat, sub_cat in zip(train_questions[:n_samples], train_categories[:n_samples], train_sub_categories[:n_samples]):\n",
        "    print(f\"\\t{question} / cat - {cat} / sub_cat - {sub_cat}\")\n",
        "\n",
        "print(f\"\\ntest_questions has {len(test_questions)} questions / {len(test_categories)} labels\")\n",
        "print(\"Some samples\")\n",
        "for question, cat, sub_cat in zip(test_questions[:n_samples], test_categories[:n_samples], test_sub_categories[:n_samples]):\n",
        "    print(f\"\\t{question} / cat - {cat} / sub_cat - {sub_cat}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jXJkE-Ao4AO"
      },
      "source": [
        "# Converting train/test data to pd.DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "F1L_Cza8o3lo"
      },
      "outputs": [],
      "source": [
        "# Define training and testing\n",
        "train_df = pd.DataFrame(\n",
        "    {'question': train_questions, 'category': train_categories, 'sub_category': train_sub_categories}\n",
        ")\n",
        "test_df = pd.DataFrame(\n",
        "    {'question': test_questions, 'category': test_categories, 'sub_category': test_sub_categories}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "g3H2G9UAo60J"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data for better randomization\n",
        "train_df = train_df.sample(frac=1.0, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QEfqoBxo_z5"
      },
      "source": [
        "# Converting string labels to integer IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Xv9WNz-Ko9yP",
        "outputId": "da3f9119-1b2c-4eb1-900c-68aae0c020dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label->ID mapping: {'DESC': 0, 'ENTY': 1, 'LOC': 2, 'NUM': 3, 'HUM': 4, 'ABBR': 5}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>sub_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5267</th>\n",
              "      <td>what is an aurora ?</td>\n",
              "      <td>0</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>what articles of clothing are tokens in monopo...</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>what causes rust ?</td>\n",
              "      <td>0</td>\n",
              "      <td>reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1356</th>\n",
              "      <td>what does an irate car owner call iron oxide ?</td>\n",
              "      <td>1</td>\n",
              "      <td>termeq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1529</th>\n",
              "      <td>what do we call the imaginary line along the t...</td>\n",
              "      <td>2</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3631</th>\n",
              "      <td>why is hockey so violent ?</td>\n",
              "      <td>0</td>\n",
              "      <td>reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4802</th>\n",
              "      <td>how many characters makes up a word for typing...</td>\n",
              "      <td>3</td>\n",
              "      <td>count</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2288</th>\n",
              "      <td>what peter blatty novel recounts the horrors o...</td>\n",
              "      <td>1</td>\n",
              "      <td>cremat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>what is measured in curies ?</td>\n",
              "      <td>0</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4472</th>\n",
              "      <td>what does seccession mean ?</td>\n",
              "      <td>0</td>\n",
              "      <td>def</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  category sub_category\n",
              "5267                                what is an aurora ?         0          def\n",
              "21    what articles of clothing are tokens in monopo...         1        other\n",
              "3258                                 what causes rust ?         0       reason\n",
              "1356     what does an irate car owner call iron oxide ?         1       termeq\n",
              "1529  what do we call the imaginary line along the t...         2        other\n",
              "3631                         why is hockey so violent ?         0       reason\n",
              "4802  how many characters makes up a word for typing...         3        count\n",
              "2288  what peter blatty novel recounts the horrors o...         1       cremat\n",
              "803                        what is measured in curies ?         0          def\n",
              "4472                        what does seccession mean ?         0          def"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate the label to ID mapping\n",
        "unique_cats = train_df[\"category\"].unique()\n",
        "labels_map = dict(zip(unique_cats, np.arange(unique_cats.shape[0])))\n",
        "print(f\"Label->ID mapping: {labels_map}\")\n",
        "\n",
        "n_classes = len(labels_map)\n",
        "\n",
        "# Convert all string labels to IDs\n",
        "train_df[\"category\"] = train_df[\"category\"].map(labels_map)\n",
        "test_df[\"category\"] = test_df[\"category\"].map(labels_map)\n",
        "\n",
        "# View some data\n",
        "train_df.head(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0NjDfgLpJ2H"
      },
      "source": [
        "# Splitting training data to train and valid subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "4_ZgQORjpJRK",
        "outputId": "56e2ac60-c2a6-4462-fd3c-e7597c033647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: (4906, 3)\n",
            "Valid size: (546, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>sub_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>what is columbia tristar 's phone number ?</td>\n",
              "      <td>3</td>\n",
              "      <td>code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2165</th>\n",
              "      <td>where do the blackhawks maintain their operati...</td>\n",
              "      <td>2</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3865</th>\n",
              "      <td>what is a softball made of ?</td>\n",
              "      <td>1</td>\n",
              "      <td>substance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5313</th>\n",
              "      <td>what happened on january 15 , 1969 ?</td>\n",
              "      <td>1</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5212</th>\n",
              "      <td>what king is satirized in the line</td>\n",
              "      <td>4</td>\n",
              "      <td>ind</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  category sub_category\n",
              "2003         what is columbia tristar 's phone number ?         3         code\n",
              "2165  where do the blackhawks maintain their operati...         2        other\n",
              "3865                       what is a softball made of ?         1    substance\n",
              "5313               what happened on january 15 , 1969 ?         1        event\n",
              "5212                 what king is satirized in the line         4          ind"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, valid_df = train_test_split(train_df, test_size=0.1)\n",
        "print(f\"Train size: {train_df.shape}\")\n",
        "print(f\"Valid size: {valid_df.shape}\")\n",
        "\n",
        "# Print data\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkcNMyKbpjoY"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6qkZKLIpi89",
        "outputId": "91298e6b-97c2-4aa0-dc4c-a99b4527f25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabluary size: 7857\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Define a tokenizer and fit on train data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df[\"question\"].tolist())\n",
        "\n",
        "# Derive the vocabulary size\n",
        "n_vocab = len(tokenizer.index_word) + 1\n",
        "print(f\"Vocabluary size: {n_vocab}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qF4mcu3jpmNf"
      },
      "outputs": [],
      "source": [
        "# Split each string by \" \", compute length of the list, get the percentiles\n",
        "train_df[\"question\"].str.split(\" \").str.len().describe(percentiles=[0.01, 0.5, 0.99])\n",
        "\n",
        "# Convert each list of tokens to a list of IDs, using tokenizer's mapping\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df[\"question\"].tolist())\n",
        "train_labels = train_df[\"category\"].values\n",
        "valid_sequences = tokenizer.texts_to_sequences(valid_df[\"question\"].tolist())\n",
        "valid_labels = valid_df[\"category\"].values\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df[\"question\"].tolist())\n",
        "test_labels = test_df[\"category\"].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85URIdNcpy4K"
      },
      "source": [
        "# Padding shorter sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Gzt2W1sepuY6"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 22\n",
        "\n",
        "# Pad shorter sentences and truncate longer ones (maximum length: max_seq_length)\n",
        "preprocessed_train_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    train_sequences, maxlen=max_seq_length, padding='post', truncating='post'\n",
        ")\n",
        "preprocessed_valid_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    valid_sequences, maxlen=max_seq_length, padding='post', truncating='post'\n",
        ")\n",
        "preprocessed_test_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    test_sequences, maxlen=max_seq_length, padding='post', truncating='post'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbzWw9wiRKmo"
      },
      "source": [
        "# Sentence classifying convolution neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BPEV8lOQB2s",
        "outputId": "69a9f04c-82e7-44a9-963d-b349a65d94a3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">502,848</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,300</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,100</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │                   │            │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m502,848\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m19,300\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m25,700\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m32,100\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │                   │            │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │      \u001b[38;5;34m1,806\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">581,754</span> (2.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m581,754\u001b[0m (2.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">581,754</span> (2.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m581,754\u001b[0m (2.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.regularizers as regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Input layer takes word IDs as inputs\n",
        "word_id_inputs = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "# Get the embeddings of the inputs / out [batch_size, sent_length, output_dim]\n",
        "embedding_out = layers.Embedding(input_dim=n_vocab, output_dim=64)(word_id_inputs)\n",
        "\n",
        "\n",
        "# For all layers: in [batch_size, sent_length, emb_size] / out [batch_size, sent_length, 100]\n",
        "conv1_1 = layers.Conv1D(\n",
        "    100, kernel_size=3, strides=1, padding='same', activation='relu'\n",
        ")(embedding_out)\n",
        "conv1_2 = layers.Conv1D(\n",
        "    100, kernel_size=4, strides=1, padding='same', activation='relu'\n",
        ")(embedding_out)\n",
        "conv1_3 = layers.Conv1D(\n",
        "    100, kernel_size=5, strides=1, padding='same', activation='relu'\n",
        ")(embedding_out)\n",
        "\n",
        "# in previous conve outputs / out [batch_size, sent_length, 300]\n",
        "conv_out = layers.Concatenate(axis=-1)([conv1_1, conv1_2, conv1_3])\n",
        "\n",
        "# Pooling over time operation. This is doing the max pooling over sequence lenth\n",
        "# in other words, each feature map results in a single output\n",
        "# in [batch_size, sent_length, 300] / out [batch_size, 1, 300]\n",
        "pool_over_time_out = layers.MaxPool1D(pool_size=max_seq_length, padding='valid')(conv_out)\n",
        "\n",
        "# Flatten the unit length dimension\n",
        "flatten_out = layers.Flatten()(pool_over_time_out)\n",
        "\n",
        "# Compute the final output\n",
        "out = layers.Dense(\n",
        "    n_classes, activation='softmax',\n",
        "    kernel_regularizer=regularizers.l2(0.001)\n",
        ")(flatten_out)\n",
        "\n",
        "# Define the model\n",
        "cnn_model = Model(inputs=word_id_inputs, outputs=out)\n",
        "\n",
        "# Compile the model with loss/optimizer/metrics\n",
        "cnn_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtDegXXFRPrq"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01IEIUpIRScd",
        "outputId": "6813cd2f-d2d1-4041-e149-966d9c8269e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.3076 - loss: 1.6815 - val_accuracy: 0.5623 - val_loss: 1.2386 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.6581 - loss: 1.1047 - val_accuracy: 0.7473 - val_loss: 0.7606 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7975 - loss: 0.6475 - val_accuracy: 0.8242 - val_loss: 0.5626 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9131 - loss: 0.3792 - val_accuracy: 0.8443 - val_loss: 0.4714 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9656 - loss: 0.2028 - val_accuracy: 0.8608 - val_loss: 0.4525 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9825 - loss: 0.1247 - val_accuracy: 0.8736 - val_loss: 0.4486 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9920 - loss: 0.0824 - val_accuracy: 0.8736 - val_loss: 0.4531 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0607 - val_accuracy: 0.8718 - val_loss: 0.4613 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m37/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9978 - loss: 0.0522\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0522 - val_accuracy: 0.8736 - val_loss: 0.4686 - learning_rate: 0.0010\n",
            "Epoch 10/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0469 - val_accuracy: 0.8736 - val_loss: 0.4684 - learning_rate: 1.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0460 - val_accuracy: 0.8755 - val_loss: 0.4688 - learning_rate: 1.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0456\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0456 - val_accuracy: 0.8755 - val_loss: 0.4694 - learning_rate: 1.0000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9999 - loss: 0.0450 - val_accuracy: 0.8755 - val_loss: 0.4695 - learning_rate: 1.0000e-05\n",
            "Epoch 14/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0450 - val_accuracy: 0.8755 - val_loss: 0.4696 - learning_rate: 1.0000e-05\n",
            "Epoch 15/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0449\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0449 - val_accuracy: 0.8755 - val_loss: 0.4696 - learning_rate: 1.0000e-05\n",
            "Epoch 16/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0455 - val_accuracy: 0.8755 - val_loss: 0.4696 - learning_rate: 1.0000e-06\n",
            "Epoch 17/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 0.0452 - val_accuracy: 0.8755 - val_loss: 0.4696 - learning_rate: 1.0000e-06\n",
            "Epoch 18/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0455\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0455 - val_accuracy: 0.8755 - val_loss: 0.4696 - learning_rate: 1.0000e-06\n",
            "Epoch 19/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0450 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n",
            "Epoch 20/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9997 - loss: 0.0452 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n",
            "Epoch 21/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0443 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n",
            "Epoch 22/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9996 - loss: 0.0458 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n",
            "Epoch 23/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0455 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n",
            "Epoch 24/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9995 - loss: 0.0461 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n",
            "Epoch 25/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0463 - val_accuracy: 0.8755 - val_loss: 0.4697 - learning_rate: 1.0000e-06\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7812b1e7deb0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Callbacks\n",
        "lr_reduce_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.1, patience=3, verbose=1,\n",
        "    mode='auto', min_delta=0.0001, min_lr=0.000001\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(\n",
        "    preprocessed_train_sequences, train_labels,\n",
        "    validation_data=(preprocessed_valid_sequences, valid_labels),\n",
        "    batch_size=128,\n",
        "    epochs=25,\n",
        "    callbacks=[lr_reduce_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl-lacrSRjhO"
      },
      "source": [
        "# Testing the model on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dCrh0QsRg24",
        "outputId": "35bf2689-5eab-4dea-90f2-d57b1301360a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.3468 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.8960000276565552, 'loss': 0.36912697553634644}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn_model.evaluate(preprocessed_test_sequences, test_labels, return_dict=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
