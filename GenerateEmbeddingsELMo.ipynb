{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jp1t5gC2Rizy"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxEW1yyZQh6w",
    "outputId": "505349af-97e5-4804-d55e-4533e71a64cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
      "env: TFHUB_CACHE_DIR=./tfhub_modules\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "# Making sure we cache the models and they are not downloaded all the time\n",
    "%env TFHUB_CACHE_DIR=./tfhub_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV4geKrXRydr"
   },
   "source": [
    "## Using pretrained ELMo model\n",
    "\n",
    "### Downloading the ELMo model from TFHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q6cNuCl6ReBB"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Remove any ongoing sessions\n",
    "K.clear_session()\n",
    "\n",
    "# Download the ELMo model and save to disk\n",
    "elmo_layer = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", signature=\"tokens\",signature_outputs_as_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNICZhMTR9ae"
   },
   "source": [
    "### Formatting the input for ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtgZcC5AR8ma",
    "outputId": "d9830906-5f40-4c57-9950-119775f3d258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': <tf.Tensor: shape=(2, 6), dtype=string, numpy=\n",
      "array([[b'the', b'cat', b'sat', b'on', b'the', b'mat'],\n",
      "       [b'the', b'mat', b'sat', b'', b'', b'']], dtype=object)>, 'sequence_len': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 3], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "def format_text_for_elmo(texts, lower=True, split=\" \", max_len=None):\n",
    "\n",
    "    \"\"\" Formats a given text for the ELMo model (takes in a list of strings) \"\"\"\n",
    "\n",
    "    token_inputs = [] # Maintains individual tokens\n",
    "    token_lengths = [] # Maintains the length of each sequence\n",
    "\n",
    "    max_len_inferred = 0 # We keep a variable to matain the max length of the input\n",
    "\n",
    "    # Go through each text (string)\n",
    "    for text in texts:\n",
    "\n",
    "        # Process the text and get a list of tokens\n",
    "        tokens = tf.keras.preprocessing.text.text_to_word_sequence(text, lower=lower, split=split)\n",
    "\n",
    "        # Add the tokens\n",
    "        token_inputs.append(tokens)\n",
    "\n",
    "        # Compute the max length for the collection of sequences\n",
    "        if len(tokens)>max_len_inferred:\n",
    "            max_len_inferred = len(tokens)\n",
    "\n",
    "    # It's important to make sure the maximum token length is only as large as the longest input in the sequence\n",
    "    # You can't have arbitrarily large length as the maximum length. Otherwise, you'll get this error.\n",
    "    #InvalidArgumentError:  Incompatible shapes: [2,6,1] vs. [2,10,1024]\n",
    "    #    [[node mul (defined at .../python3.6/site-packages/tensorflow_hub/module_v2.py:106) ]] [Op:__inference_pruned_3391]\n",
    "\n",
    "    # Here we make sure max_len is only as large as the longest input\n",
    "    if max_len and max_len_inferred < max_len:\n",
    "        max_len = max_len_inferred\n",
    "    if not max_len:\n",
    "        max_len = max_len_inferred\n",
    "\n",
    "    # Go through each token sequence and modify sequences to have same length\n",
    "    for i, token_seq in enumerate(token_inputs):\n",
    "\n",
    "        token_lengths.append(min(len(token_seq), max_len))\n",
    "\n",
    "        # If the maximum length is less than input length, truncate\n",
    "        if max_len < len(token_seq):\n",
    "            token_seq = token_seq[:max_len]\n",
    "        # If the maximum length is greater than or equal to input length, add padding as needed\n",
    "        else:\n",
    "            token_seq = token_seq+[\"\"]*(max_len-len(token_seq))\n",
    "\n",
    "        assert len(token_seq)==max_len\n",
    "\n",
    "        token_inputs[i] = token_seq\n",
    "\n",
    "    # Return the final output\n",
    "    return {\n",
    "        \"tokens\": tf.constant(token_inputs),\n",
    "        \"sequence_len\": tf.constant(token_lengths)\n",
    "    }\n",
    "\n",
    "\n",
    "print(format_text_for_elmo([\"the cat sat on the mat\", \"the mat sat\"], max_len=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpD7jiWNSjWj",
    "outputId": "106d4b78-6415-4748-b9fd-3928745fc135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor under key=word_emb is a (5, 6, 512) shaped Tensor\n",
      "Tensor under key=default is a (5, 1024) shaped Tensor\n",
      "Tensor under key=elmo is a (5, 6, 1024) shaped Tensor\n",
      "Tensor under key=lstm_outputs2 is a (5, 6, 1024) shaped Tensor\n",
      "Tensor under key=lstm_outputs1 is a (5, 6, 1024) shaped Tensor\n",
      "Tensor under key=sequence_len is a (5,) shaped Tensor\n"
     ]
    }
   ],
   "source": [
    "# Titles of 001.txt - 005.txt in bbc/business\n",
    "elmo_inputs = format_text_for_elmo([\n",
    "    \"Ad sales boost Time Warner profit\",\n",
    "    \"Dollar gains on Greenspan speech\",\n",
    "    \"Yukos unit buyer faces loan claim\",\n",
    "    \"High fuel prices hit BA's profits\",\n",
    "    \"Pernod takeover talk lifts Domecq\"\n",
    "])\n",
    "\n",
    "# Get the result from ELMo\n",
    "elmo_result = elmo_layer(elmo_inputs)\n",
    "\n",
    "# Print the result\n",
    "for k,v in elmo_result.items():\n",
    "    print(f\"Tensor under key={k} is a {v.shape} shaped Tensor\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
